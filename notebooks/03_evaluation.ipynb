{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f57e8f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\"\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "seen = set()\n",
    "new_path = []\n",
    "for p in sys.path:\n",
    "    if p not in seen:\n",
    "        new_path.append(p)\n",
    "        seen.add(p)\n",
    "sys.path = new_path\n",
    "\n",
    "from rag_pipeline import ingestion, embedding, retrieval, generator, evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f447156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "# 1. Load QA dataset\n",
    "questions, answers = evaluation.load_qa_dataset(\"../data/qa_dataset.csv\")\n",
    "\n",
    "# 2. Load sample docs & build vectorstore\n",
    "doc_path = '..\\data\\sample_docs'\n",
    "chunks = ingestion.load_and_chunk(doc_path)\n",
    "\n",
    "print(f\"Number of chunks: {len(chunks)}\")\n",
    "if len(chunks) == 0:\n",
    "    raise ValueError(\"No document chunks found! Check your document loading/splitting.\")\n",
    "\n",
    "emb = embedding.HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "vectorstore = retrieval.build_faiss_index(chunks, emb)\n",
    "\n",
    "# 3. Load LLM\n",
    "llm = generator.load_generator()\n",
    "\n",
    "\"\"\"\n",
    "# Test single query generation to see output\n",
    "sample_query = \"What is 5G?\"\n",
    "sample_context = vectorstore.similarity_search(sample_query, k=3)\n",
    "answer = generator.generate_answer(llm, sample_query, sample_context)\n",
    "print(\"Sample generated answer:\", answer)\n",
    "\"\"\"\n",
    "\n",
    "# 4. Evaluate baseline (LLM only)\n",
    "baseline_scores = evaluation.evaluate_model(questions, answers, llm)\n",
    "\n",
    "# 5. Evaluate RAG\n",
    "rag_scores = evaluation.evaluate_model(questions, answers, llm, vectorstore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7aa6172d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Example Score: {'rouge': {'rouge1': np.float64(0.3333333333333333), 'rouge2': np.float64(0.0), 'rougeL': np.float64(0.16666666666666666), 'rougeLsum': np.float64(0.16666666666666666)}, 'bertscore': {'precision': [0.8721495866775513], 'recall': [0.884736180305481], 'f1': [0.8783978223800659], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.53.1)'}}\n",
      "RAG Example Score: {'rouge': {'rouge1': np.float64(0.0326530612244898), 'rouge2': np.float64(0.020491803278688523), 'rougeL': np.float64(0.0326530612244898), 'rougeLsum': np.float64(0.0326530612244898)}, 'bertscore': {'precision': [0.7572565078735352], 'recall': [0.9105463624000549], 'f1': [0.8268569111824036], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.53.1)'}}\n"
     ]
    }
   ],
   "source": [
    "print(\"Baseline Example Score:\", baseline_scores[0])\n",
    "print(\"RAG Example Score:\", rag_scores[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
